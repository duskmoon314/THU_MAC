{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from sklearn import svm\n",
    "from skimage.feature import hog\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import json\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading category :i2\n",
      "loading category :i4\n",
      "loading category :i5\n",
      "loading category :io\n",
      "loading category :ip\n",
      "loading category :p11\n",
      "loading category :p23\n",
      "loading category :p26\n",
      "loading category :p5\n",
      "loading category :pl30\n",
      "loading category :pl40\n",
      "loading category :pl5\n",
      "loading category :pl50\n",
      "loading category :pl60\n",
      "loading category :pl80\n",
      "loading category :pn\n",
      "loading category :pne\n",
      "loading category :po\n",
      "loading category :w57\n",
      "success!\n"
     ]
    }
   ],
   "source": [
    "DATA_TRAIN = 'image_exp/Classification/Data/Train'\n",
    "\n",
    "train_data = []\n",
    "categroies = os.listdir(DATA_TRAIN)\n",
    "\n",
    "# load training data\n",
    "\n",
    "for category in categroies:\n",
    "    path = os.path.join(DATA_TRAIN, category)\n",
    "    print('loading category :' + category)\n",
    "    for file in os.listdir(path):\n",
    "        img = cv2.imread(os.path.join(path, file))\n",
    "        img = cv2.resize(img, (60, 60)) # average size\n",
    "        fd = hog(img, orientations=9, pixels_per_cell=(6, 6),\n",
    "                    cells_per_block=(2, 2), multichannel=True)\n",
    "        train_data.append((fd, category))\n",
    "\n",
    "random.shuffle(train_data)\n",
    "print('success!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10124\n",
      "4339\n"
     ]
    }
   ],
   "source": [
    "# divide into train and validation\n",
    "\n",
    "n = int(0.7 * len(train_data))\n",
    "train_set = train_data[:n]\n",
    "val_set = train_data[n:]\n",
    "\n",
    "print(len(train_set))\n",
    "print(len(val_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unzip dataset\n",
    "X_train, Y_train = map(list, zip(*train_set))\n",
    "X_train = np.array(X_train)\n",
    "Y_train = np.array(Y_train)\n",
    "\n",
    "X_test, Y_test = map(list, zip(*val_set))\n",
    "X_test = np.array(X_test)\n",
    "Y_test = np.array(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = svm.SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9589767227471768\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "for i in range(len(X_test)):\n",
    "    if predicted[i] == Y_test[i]:\n",
    "        correct += 1\n",
    "\n",
    "print(correct/len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tsinghuaee221/myminiconda/envs/ml/lib/python3.7/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['exp1.model']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save model\n",
    "from sklearn.externals import joblib\n",
    "joblib.dump(classifier,'exp1.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3800 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading test images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3800/3800 [01:25<00:00, 44.23it/s] \n"
     ]
    }
   ],
   "source": [
    "classifier = joblib.load('exp1.model')\n",
    "DATA_TEST = 'image_exp/Classification/Data/Test'\n",
    "test_data = []\n",
    "test_imgs = os.listdir(DATA_TEST)\n",
    "print('loading test images')\n",
    "for i in tqdm(range(len(test_imgs))):\n",
    "    path = os.path.join(DATA_TEST, test_imgs[i])\n",
    "    img = cv2.imread(path)\n",
    "    img = cv2.resize(img, (60, 60)) # average size\n",
    "    fd = hog(img, orientations=9, pixels_per_cell=(6, 6),\n",
    "                cells_per_block=(2, 2), multichannel=True)\n",
    "    test_data.append(fd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing...\n"
     ]
    }
   ],
   "source": [
    "print('testing...')\n",
    "test_predict = classifier.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3800/3800 [00:00<00:00, 1047335.73it/s]\n"
     ]
    }
   ],
   "source": [
    "test_result = {}\n",
    "for i in tqdm(range(len(test_imgs))):\n",
    "    test_result[test_imgs[i]] = test_predict[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(test_result, open('exp1_test.json','w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
